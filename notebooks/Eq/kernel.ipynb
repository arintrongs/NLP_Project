{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.txt', 'train_label.txt', 'train.txt', 'test_majority.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/wisesight-sentiment\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = open(\"../input/wisesight-sentiment/train.txt\", \"r\")\n",
    "train_label_text = open(\"../input/wisesight-sentiment/train_label.txt\", \"r\")\n",
    "test_text = open(\"../input/wisesight-sentiment/test.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c595c2cf2fef09aff931db68ebc76a7a92ea020b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "64f8605aafb5a2b4e30f59ae0c96500fb41c1175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pythainlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/01/c48fd12dfe7f3ccf8795c657aa8c7961784c58f71c3b7e4f895723fd88b9/pythainlp-1.7.4-py3-none-any.whl (10.3MB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.3MB 4.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from pythainlp) (1.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pythainlp) (2.21.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from pythainlp) (0.2.9)\n",
      "Requirement already satisfied: marisa-trie in /opt/conda/lib/python3.6/site-packages (from pythainlp) (0.7.5)\n",
      "Collecting tinydb (from pythainlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/2b/98040184cfbf03113736a160ea35aa92dc3619312ba5a4d6cafaf7f81c73/tinydb-3.12.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from pythainlp) (2018.4)\n",
      "Requirement already satisfied: future>=0.16.0 in /opt/conda/lib/python3.6/site-packages (from pythainlp) (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.2.2 in /opt/conda/lib/python3.6/site-packages (from pythainlp) (3.2.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pythainlp) (4.31.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pythainlp) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pythainlp) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pythainlp) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pythainlp) (1.22)\n",
      "Installing collected packages: tinydb, pythainlp\n",
      "Successfully installed pythainlp-1.7.4 tinydb-3.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5aedf72fccd39181889f6bd7e08ef5c418b5d82a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = []\n",
    "label = []\n",
    "test = []\n",
    "for line in train_text:\n",
    "    sentence.append(line.strip())\n",
    "for line in train_label_text:\n",
    "    label.append(line.strip())\n",
    "for line in test_text:\n",
    "    test.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "02aacfea38ae10eda7f8cb41f000e6e5183b0aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                sentence label\n",
      "0      10 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏Æ‡∏±‡∏ö‡∏°‡∏∞‡∏Å‡∏≠‡∏Å ‡πÄ‡∏Å‡∏£‡∏î A ‡∏à‡∏≤‡∏Å‡∏ï‡∏∏‡∏£‡∏Å‡∏µ 1. ‡∏ä‡πà‡∏ß‡∏¢...   neu\n",
      "1      ‡∏Ç‡∏±‡∏ö‡∏≠‡∏±‡∏•‡∏ï‡∏¥‡∏™1.8/141‡∏°‡πâ‡∏≤ ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡πÄ‡∏à‡∏≠‡∏Å‡∏∞‡∏ö‡∏∞‡∏Å‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡πÑ‡∏ü‡πÉ‡∏£‡πà‡∏ï‡∏≤‡∏°...   neg\n",
      "2      ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏Å‡∏±‡∏ô‡πÑ‡∏õ‡∏ô‡∏≤‡∏ô‡πÜ‡∏ô‡∏∞ ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÉ‡∏ô‡πÄ‡∏´‡∏á‡∏≤ ‡∏≠‡∏¢‡∏π...   neu\n",
      "3                             ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏•‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö mg3‡∏ä‡∏±‡∏î‡∏ä‡∏±‡∏î   neu\n",
      "4           ,, ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏î‡∏µ‡∏Å‡∏±‡∏ö BLEND285 ‡∏à‡∏±‡∏á ‡πÄ‡∏•‡∏¢‡∏à‡πä‡∏∞‡∏û‡∏µ‡πà‡∏à‡πã‡∏≤   neu\n",
      "5      ‡πÑ‡∏°‡πà‡∏Å‡∏•‡πâ‡∏≤‡∏Å‡∏¥‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡πà‡∏∞ ‡∏Å‡∏•‡∏±‡∏ß‡∏ß‡∏ß‡∏ß‡∏ß‡∏ß‡∏ï‡∏≤‡∏¢ ‡πÅ‡∏ñ‡∏°‡∏Å‡∏≤‡∏£‡∏ä‡∏µ‡πâ‡πÅ‡∏à‡∏á‡∏à‡∏∞‡∏≠...   neu\n",
      "6      ***** ‡∏°‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏∞ ‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏°‡∏î‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞*** Bvlgari ...   neu\n",
      "7                                              ‡∏Ñ‡∏£‡∏π‡∏à‡πã‡∏≤‡∏≤‡∏≤‡∏≤   neu\n",
      "8                 ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏±‡πà‡∏á‡∏à‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏ö‡πâ‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞   neu\n",
      "9      ‡∏Å‡πá‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏ô‡∏∞ ‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏ô‡πà‡∏≤‡∏Å‡∏¥‡∏ô‡∏™‡∏∏‡∏î‡πÜ ‡πÄ‡∏´...   pos\n",
      "10                  ‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á Hot Pot Value ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤...   neu\n",
      "11                         ‡πÄ‡∏≠‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à‡∏°‡∏µ‡πÄ‡∏ö‡∏µ‡∏¢‡∏£‡πå‡∏ä‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°   neu\n",
      "12     ‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÅ‡∏´‡πà‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏•‡πÇ‡∏•‡∏¢‡∏µ Sm...   neu\n",
      "13             ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÄ‡∏°‡∏∑‡πà‡∏≠ Honda ‡∏°‡∏≤‡∏ó‡∏≥‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏µ‡πÄ‡∏ã‡∏•   neu\n",
      "14     ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏ó...   neg\n",
      "15     ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏ô‡∏π‡πÑ‡∏´‡∏ô‡∏Ç‡∏≠‡∏áBarBQ Plaza ‡∏Å‡πá‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏ñ‡∏π‡∏Å‡πÉ‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±...   pos\n",
      "16                       ‡πÇ‡∏ï‡πÇ‡∏¢‡∏ï‡πâ‡∏≤‡∏ß‡∏¥‡πÇ‡∏Å‡πâ4‡∏õ‡∏∞‡∏ï‡∏π‡∏™‡πà‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£     q\n",
      "17     ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏°‡πâ‡∏ô‡∏î‡∏¥‡∏°‡∏µ‡πÄ‡∏à‡∏≠‡πÅ‡∏°‡∏•‡∏á‡∏™‡∏≤‡∏õ‡πÉ‡∏ô‡πÄ‡∏ï‡∏≤‡∏î‡πâ‡∏ß‡∏¢ ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏ô‡∏Å‡πá‡πÄ‡∏à‡∏≠‡πÑ‡∏ï‡πà‡∏≠...   neg\n",
      "18     ‡∏ö‡∏∏‡∏´‡∏£‡∏µ‡πà ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á...   neu\n",
      "19                                        ‡πÄ‡∏≠‡∏≠‡∏≠ ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò   neu\n",
      "20     ‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏¥‡∏ù‡∏≤‡∏Å‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞ ‡πÉ‡∏Ñ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡∏Å‡∏Ç‡∏≤‡∏ß ‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á...   neg\n",
      "21     ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏ò‡∏≠‡πÄ‡∏™‡∏°‡∏≠‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà...   neu\n",
      "22                                             ‡∏´‡∏±‡∏ß‡∏ô‡∏° ‡∏ï‡∏π‡∏î   neu\n",
      "23     üêò#‡∏ä‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ‡∏≠‡∏µ‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡πâ‡∏≤‡∏ö #‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏´‡∏≤‡∏ö‡∏±‡∏ï‡∏£‡∏Å‡∏±‡∏ô‡∏ö‡∏±‡∏î‡∏ô...   neu\n",
      "24     ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö1 ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏Ñ‡∏∏‡∏Å‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÑ‡∏´‡∏° ‡∏ò‡∏£‡∏£‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏®...   neu\n",
      "25                   Blend ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠‡πÄ‡∏´‡∏•‡πâ‡∏≤ blend285 haha   neu\n",
      "26                                    ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ üôèüèª   neu\n",
      "27     #‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô ‡∏ü‡∏±‡∏á‡∏î‡∏π‡πÅ‡∏•...   neu\n",
      "28                           ‡πÇ‡∏ö‡∏Å‡πÅ‡∏ó‡πá‡∏Å‡∏ã‡∏µ‡πà‡∏™‡∏¥‡∏ö‡∏Ñ‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏õ‡∏ã‡∏±‡∏Å‡∏Ñ‡∏±‡∏ô   neg\n",
      "29                                    ‡πÉ‡∏ô‚Äã Lazada‚Äã ‡πÅ‡∏≠‡∏õ‡∏Ñ‡πà‡∏≤   neu\n",
      "...                                                  ...   ...\n",
      "24315  ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡∏Å‡πâ‡∏≠‡∏ô‡∏à‡∏±‡∏î‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏£‡∏µ‡∏ü‡∏¥‡∏• 2 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö 1) ‡πÇ...   neu\n",
      "24316                            ‡∏ô‡∏∂‡∏Å‡∏ß‡πà‡∏≤ Subaru XV ‡∏Æ‡πà‡∏≤‡πÜ üòÇ   neu\n",
      "24317                                 ‡πÑ‡∏°‡πà‡∏Å‡∏¥‡∏ô‡∏´‡∏°‡∏π‡∏Å‡∏∞‡∏ó‡∏∞‡∏∞‡∏∞‡∏∞‡∏∞‡∏∞   neg\n",
      "24318                           ‡∏û‡∏±‡∏Å‡∏û‡∏£‡πâ‡∏≠‡∏°‚Äã‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô.. ‡∏à‡∏±‡∏î‡πÄ‡∏•‡∏¢   pos\n",
      "24319                                 ‡πÑ‡∏´‡∏ô‡πÜ‡∏Ç‡∏≠‡∏•‡∏≠‡∏á‡∏™‡∏±‡∏Å‡πÄ‡∏õ‡πä‡∏Å‡∏™‡∏¥   neu\n",
      "24320                                            ‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏°‡∏≠   pos\n",
      "24321  ‡∏™‡∏á‡∏Å‡∏£‡∏≤‡∏ô‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏à‡∏≠‡∏Å‡∏±‡∏ô‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á‡∏´‡πà‡∏ß...   neu\n",
      "24322  ‡∏´‡∏•‡∏∏‡∏î Nissan Sylphy EV 2018 ‡πÉ‡∏´‡∏°‡πà ‡∏Ñ‡∏≤‡∏î‡∏ß‡∏¥‡πà‡∏á‡πÑ‡∏Å‡∏• 200...   neu\n",
      "24323                           55555‡πÅ‡∏î‡∏Å‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡∏¢‡πà‡∏≤‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏±‡πâ‡∏ô   neu\n",
      "24324                          ‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏î‡∏î ‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏°‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏≤   neu\n",
      "24325  ‡∏Ñ‡∏∑‡∏≠ ‡∏ä‡∏ô‡∏≤‡∏ò‡∏¥‡∏õ ‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏ô‡∏µ‡πà‡∏Ñ‡∏•‡πà‡∏≠‡∏á‡πÅ‡∏Ñ‡∏•‡πà‡∏ß ‡πÄ‡∏ä‡∏µ‡∏¢‡∏ß #swiftzak...   neu\n",
      "24326                         ‡πÄ‡∏™‡∏µ‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏ï‡∏≤‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö     q\n",
      "24327                                         ‡∏à‡∏∞‡∏ó‡∏±‡∏ô‡∏°‡∏≤‡∏°‡πà‡∏∞   neu\n",
      "24328  ‡∏Å‡∏î‡πÄ‡∏ö‡∏µ‡∏¢‡∏£‡πå‡∏™‡∏î‡∏•‡∏µ‡πÇ‡∏≠‡πÉ‡∏ô‡πÄ‡∏ã‡πÄ‡∏ß‡πà‡∏ô‡πÄ‡∏£‡∏≤‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ß‡πà‡∏∞ ‡∏à‡∏∞‡∏î‡πà‡∏≤‡∏ß...   neg\n",
      "24329  ‡∏°‡∏≤‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Å‡πá‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏≠‡∏∞‡πÑ‡∏£ ‡πÅ‡∏°‡πâ‡πÄ‡∏ã‡∏ü‡∏ï‡∏µ‡πâ‡∏à‡∏∞‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Ñ...   neg\n",
      "24330  ‡∏ô‡∏±‡πà‡∏ô‡πÑ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö!!!! ‡πÅ‡∏°‡πà‡∏á‡∏´‡∏≤‡∏Ñ‡∏ô‡∏´‡∏≤‡∏£‡∏ö‡∏≤‡∏Ñ‡∏≤‡∏î‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏π‡∏Å‡πá‡πÇ‡∏î‡∏ô‡∏î‡πâ...   neg\n",
      "24331                               ‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏õ‡∏£‡∏ß‡∏±‡∏ô‡∏û‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡πà‡∏∞   pos\n",
      "24332                         ‡∏Å‡πä‡∏ß‡∏ô‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏î‡∏∑‡πà‡∏° ‡πÑ‡∏Æ‡πÄ‡∏ô‡πÄ‡∏Å‡πâ‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö   neg\n",
      "24333                                            ‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏≠‡∏á   neu\n",
      "24334                         ‡∏£‡∏µ‡∏ö‡πÑ‡∏õ ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Ç‡∏±‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏î‡πÄ‡∏£‡∏ô‡πÄ‡∏à‡∏≠‡∏£‡πå   neu\n",
      "24335                                     ‡∏°‡∏µ‡∏õ‡∏¥‡πâ‡∏á‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢   neu\n",
      "24336  ‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡∏°‡∏±‡∏ô‡∏ú‡∏π‡∏Å‡∏Ç‡∏≤‡∏î‡∏≠‡∏¢‡∏π‡πà3‡∏£‡∏≤‡∏¢‡πÅ‡∏Ñ‡πà‡∏ô‡∏±‡πâ‡∏ô ‡∏ã‡∏µ ‡∏û‡∏µ ‡πÄ‡∏ö‡∏µ‡∏¢‡∏£‡πå‡∏ä...   neu\n",
      "24337  ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏¥‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ï‡∏π‡∏´‡∏£‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏û‡∏ß‡∏Å‡πÄ‡∏ô‡∏µ‡πà‡∏¢ ‡∏ï‡∏π‡πÉ‡∏ä‡πâ‡πÇ‡∏≠‡πÄ‡∏•‡∏¢‡πå ‡∏ã‡∏≠‡∏á...   neu\n",
      "24338  ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß Toyota CH-R http://acarnewsonline.com/te...   neu\n",
      "24339  The toys the parkinson ‡πÄ‡∏õ‡πâ &‡∏õ‡∏µ‡∏®‡∏≤‡∏à‡πÅ‡∏ö‡∏ô‡∏î‡πå ‡∏ä‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°...   pos\n",
      "24340                                             ‡∏ä‡∏ß‡∏ô‡πÉ‡∏Ñ‡∏£   neu\n",
      "24341  ‡∏õ‡∏π‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á‡πÉ‡∏ô‡∏ó‡πà‡∏≠‡∏â‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏µ‡∏ò‡∏¥‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ...   neu\n",
      "24342     ‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡∏±‡∏ô‡∏û‡πà‡∏≠‡∏õ‡∏µ‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡∏≠‡∏∞‡πÑ‡∏£‡∏´‡∏£‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏à‡∏¥‡∏á‡πÜ   neg\n",
      "24343  ‡∏£‡∏ñ‡∏ú‡∏°HRV ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏≠‡∏≠‡∏Å‡∏£‡∏ñ ‡∏ä‡πà‡∏ß‡∏á‡∏•‡πà‡∏≤‡∏á‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á...   neg\n",
      "24344                                        ‡πÄ‡∏û‡∏≠‡∏£‡∏¥‡πÄ‡∏û‡∏≠‡∏£‡πà‡∏≤   neu\n",
      "\n",
      "[24345 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'sentence':sentence,'label':label}\n",
    "df = pd.DataFrame(data)\n",
    "print (df)\n",
    "data_test = {'test':test}\n",
    "df_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "f9cbcd7dcd9df0f52f097e23889f51591e11e510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‡∏â‡∏±‡∏ô', '‡∏£‡∏±‡∏Å', '‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢', '‡πÄ‡∏û‡∏£‡∏≤‡∏∞', '‡∏â‡∏±‡∏ô', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "a = '‡∏â‡∏±‡∏ô‡∏£‡∏±‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢' # u'‡∏â‡∏±‡∏ô‡∏£‡∏±‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢' ‡πÉ‡∏ô Python 2.7\n",
    "b = word_tokenize(a)\n",
    "print(b) # ['‡∏â‡∏±‡∏ô', '‡∏£‡∏±‡∏Å', '‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢', '‡πÄ‡∏û‡∏£‡∏≤‡∏∞', '‡∏â‡∏±‡∏ô', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2f499338aadabb42d3038195c2d47e391b8071fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24183</td>\n",
       "      <td>24183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>24183</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>‡∏ô‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô ‡∏û‡∏≤‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏õ‡∏Å‡∏¥‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>14163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Input  Label\n",
       "count                          24183  24183\n",
       "unique                         24183      4\n",
       "top     ‡∏ô‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô ‡∏û‡∏≤‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏õ‡∏Å‡∏¥‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢    neu\n",
       "freq                               1  14163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = df\n",
    "data_df['clean_label']=data_df['label'].str.lower().copy()\n",
    "data_df.drop('label', axis=1, inplace=True)\n",
    "data_df.columns = ['Input','Label']\n",
    "data_df = data_df.drop_duplicates(\"Input\", keep=\"first\")\n",
    "display(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "16095a6096b2d663a7772c544f7452e7b7622471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mappings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neu': 0, 'neg': 1, 'pos': 2, 'q': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 'neu', 1: 'neg', 2: 'pos', 3: 'q'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Mappings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neu', 'neg', 'neu', ..., 'neg', 'neg', 'neu'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Mappings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 0], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(data_df.as_matrix(), copy=True)\n",
    "data_test = np.array(df_test.as_matrix(), copy=True)\n",
    "\n",
    "action_unique_label = data_df.Label.unique()\n",
    "\n",
    "action_label_2_num_map = dict(zip(action_unique_label, range(len(action_unique_label))))\n",
    "action_num_2_label_map = dict(zip(range(len(action_unique_label)), action_unique_label))\n",
    "\n",
    "print(\"Create Mappings\")\n",
    "display(action_label_2_num_map)\n",
    "display(action_num_2_label_map)\n",
    "\n",
    "print(\"Before Mappings\")\n",
    "display(data[:, 1])\n",
    "data[:,1] = np.vectorize(action_label_2_num_map.get)(data[:,1])\n",
    "\n",
    "print(\"After Mappings\")\n",
    "display(data[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1f1985d6e4bf4a15b9175acf46b4ad6e8df8834b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_word = []\n",
    "for x in sentence:\n",
    "    b = word_tokenize(x)\n",
    "    for i in b:\n",
    "        all_word.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "13725be1c13e7b673fbd00f15ef30fb0ccaa5641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8322\n"
     ]
    }
   ],
   "source": [
    "all_word_uniq = np.unique(all_word)\n",
    "\n",
    "all_word_final = []\n",
    "str_char, str_char_count = np.unique(all_word, return_counts=True)\n",
    "for char, count in zip(str_char, str_char_count):\n",
    "    if count >= 5:\n",
    "        all_word_final.append(char)\n",
    "print(len(all_word_final))\n",
    "all_word_final = np.array(list(all_word_final))\n",
    "all_word_final = np.unique(all_word_final)\n",
    "sorted(all_word_final)\n",
    "word_map = dict(zip(all_word_final, range(len(all_word_final))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "63142e01b0b261e7abc1c361778ce05ff36609bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example String to feature conversion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏Æ‡∏±‡∏ö‡∏°‡∏∞‡∏Å‡∏≠‡∏Å ‡πÄ‡∏Å‡∏£‡∏î A ‡∏à‡∏≤‡∏Å‡∏ï‡∏∏‡∏£‡∏Å‡∏µ 1. ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô 2. ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡∏´‡∏±‡∏ß‡πÉ‡∏à 3. ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á 4. ‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ú‡∏¥‡∏ß‡∏û‡∏£‡∏£‡∏ì‡πÅ‡∏ö‡∏ö Inside-Out 5. ‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏™‡∏°‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ‡∏≠‡∏±‡∏•‡πÑ‡∏ã‡πÄ‡∏°‡∏≠‡∏£‡πå 6. ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏∞‡∏•‡∏≤‡∏¢‡πÑ‡∏Ç‡∏°‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ 7. ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÅ‡∏ö‡∏Ñ‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤‡πÉ‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ 8. ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ô‡∏ó‡πâ‡∏≠‡∏á ‡πÄ‡∏ä‡πà‡∏ô‡∏ó‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏© 9. ‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡πÄ‡∏´‡∏ô‡πá‡∏ö‡∏ä‡∏≤ 10. ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏û‡πâ ‡πÅ‡∏•‡∏∞‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ã‡∏ô‡∏±‡∏™'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([32.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_word(string):\n",
    "    global all_char, char_map\n",
    "    result = np.zeros(len(all_word_final))\n",
    "    b = word_tokenize(string)\n",
    "    np_str = np.array(b)\n",
    "    str_char, str_char_count = np.unique(np_str, return_counts=True)\n",
    "    for char, count in zip(str_char, str_char_count):\n",
    "        try:\n",
    "            result[word_map[char]] = count\n",
    "#             print(count,char)\n",
    "        except:\n",
    "            aaa = 5\n",
    "    return result\n",
    "\n",
    "# run example feature transformation\n",
    "print(\"Example String to feature conversion\")\n",
    "display(data[0, 0])\n",
    "display(count_word(data[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b27421073157cc2bff3385ced134c83a641f5955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Data shape (24183, 8322)\n",
      "label shape (24183,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.vectorize(count_word, otypes=[object])(data[:, 0])\n",
    "x_f1 = np.array([[e for e in sl] for sl in temp.tolist()])\n",
    "\n",
    "temp = np.vectorize(count_word, otypes=[object])(data_test[:, 0])\n",
    "x_f1_test = np.array([[e for e in sl] for sl in temp.tolist()])\n",
    "\n",
    "action_label = data[:, 1]\n",
    "print(\"Data\")\n",
    "print(\"Data shape\", x_f1.shape)\n",
    "print(\"label shape\", action_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "97ed647cbd662861f342bb94725acba52779819a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "action_train_f1, action_test_f1 = train_test_split(x_f1, test_size=0.1,random_state=42)\n",
    "action_train_label, action_test_label = train_test_split(action_label, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "7b7e9dc59c2dce383578c7e2bd21fdec35b18d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21764,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "b57a3c5996f42a4abc5d2fa9ac8f6a3893becede",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_label(label,class_type):\n",
    "    result = np.zeros(len(data_df.Label.unique()))\n",
    "    result[int(label)] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "d0c1591b2a93c78532ca765e2e80ed2fc93cadac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.vectorize(onehot_label, otypes=[object])(action_train_label,'Label')\n",
    "action_y_train = np.array([[e for e in sl] for sl in temp.tolist()])\n",
    "temp = np.vectorize(onehot_label, otypes=[object])(action_test_label,'Label')\n",
    "action_y_test = np.array([[e for e in sl] for sl in temp.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "b6e8a8992fe3e9f4d6254682135f5d85dc0a69e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(action_train_f1.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(len(data_df.Label.unique())))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "0fb021f2d49e6b9c86e789fe8288d1f786abe2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21764 samples, validate on 2419 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.8230 - acc: 0.6827 - val_loss: 0.6804 - val_acc: 0.7342\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68042, saving model to model.h5\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.5922 - acc: 0.7669 - val_loss: 0.6798 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68042 to 0.67976, saving model to model.h5\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.4391 - acc: 0.8237 - val_loss: 0.7373 - val_acc: 0.7255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67976\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3079 - acc: 0.8774 - val_loss: 0.8830 - val_acc: 0.7375\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67976\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.2244 - acc: 0.9139 - val_loss: 1.0333 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67976\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.1729 - acc: 0.9366 - val_loss: 1.1956 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.67976\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.1473 - acc: 0.9464 - val_loss: 1.2129 - val_acc: 0.7115\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.67976\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.1194 - acc: 0.9572 - val_loss: 1.2173 - val_acc: 0.7152\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.67976\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.1049 - acc: 0.9622 - val_loss: 1.3830 - val_acc: 0.7152\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.67976\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0940 - acc: 0.9672 - val_loss: 1.5164 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.67976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f299ff5c6a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('model.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "model.fit(action_train_f1,action_y_train, validation_data=(action_test_f1, action_y_test), callbacks=[checkpoint],epochs=10,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "79261911b353499705522c44cf0635757a63c0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288135593220338\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(action_test_f1)\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "y_true = np.argmax(action_y_test,axis = 1)\n",
    "print(f1_score(y_true,y_pred,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "cd5dab0f77704f64fafe1f8dcb54a52e19459ae1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_f1_test)\n",
    "y_pred = np.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a1b3f7806507d17795739ae1699d72f7ebcd0444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3946"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "f2843b2ec89334ecd266d34f229b6f9e7d03cf41",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'neu', 1: 'neg', 2: 'pos', 3: 'q'}\n",
      "        Id Class\n",
      "0        1   neu\n",
      "1        2   neu\n",
      "2        3   neu\n",
      "3        4   neu\n",
      "4        5   neu\n",
      "5        6   pos\n",
      "6        7   neu\n",
      "7        8   neg\n",
      "8        9   pos\n",
      "9       10   neg\n",
      "10      11   neu\n",
      "11      12   neu\n",
      "12      13   pos\n",
      "13      14   neu\n",
      "14      15   neu\n",
      "15      16   neu\n",
      "16      17   neg\n",
      "17      18   neg\n",
      "18      19   neu\n",
      "19      20   neg\n",
      "20      21   neg\n",
      "21      22   neu\n",
      "22      23   neg\n",
      "23      24   neg\n",
      "24      25   neu\n",
      "25      26   neu\n",
      "26      27   neu\n",
      "27      28   neu\n",
      "28      29   neu\n",
      "29      30   neu\n",
      "...    ...   ...\n",
      "3916  3917   pos\n",
      "3917  3918   neu\n",
      "3918  3919   neu\n",
      "3919  3920   neu\n",
      "3920  3921   neu\n",
      "3921  3922   neu\n",
      "3922  3923   neu\n",
      "3923  3924   neu\n",
      "3924  3925   neu\n",
      "3925  3926   neu\n",
      "3926  3927   neu\n",
      "3927  3928   neu\n",
      "3928  3929   neu\n",
      "3929  3930   neu\n",
      "3930  3931   neu\n",
      "3931  3932   neg\n",
      "3932  3933   neu\n",
      "3933  3934   neu\n",
      "3934  3935   neu\n",
      "3935  3936   neg\n",
      "3936  3937   neu\n",
      "3937  3938   neu\n",
      "3938  3939   neu\n",
      "3939  3940     q\n",
      "3940  3941   neu\n",
      "3941  3942   neu\n",
      "3942  3943   neu\n",
      "3943  3944   pos\n",
      "3944  3945   pos\n",
      "3945  3946   neg\n",
      "\n",
      "[3946 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(action_num_2_label_map)\n",
    "idx = 1\n",
    "Id = []\n",
    "Class = []\n",
    "for x in y_pred:\n",
    "    Id.append(idx)\n",
    "    Class.append(action_num_2_label_map[x])\n",
    "    idx += 1\n",
    "data = {'Id':Id,'Class':Class}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "export_csv = df.to_csv ('export_dataframe.csv', index = None, header=True) \n",
    "\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edab19e404173ac15b8166b12e1f35a5ab473822",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
