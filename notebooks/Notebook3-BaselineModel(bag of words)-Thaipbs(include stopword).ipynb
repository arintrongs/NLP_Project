{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import codecs\n",
    "import collections\n",
    "import keras.preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense,GRU,Reshape,TimeDistributed,Bidirectional,Dropout,Masking\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Embedding,TimeDistributed,Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense, Masking\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import Embedding,TimeDistributed,Flatten\n",
    "from keras.layers import BatchNormalization,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pbs = pd.read_csv('Thaipbs-tokenize_include_stop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pbs.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>DOW</th>\n",
       "      <th>time</th>\n",
       "      <th>view</th>\n",
       "      <th>category</th>\n",
       "      <th>tag</th>\n",
       "      <th>hour</th>\n",
       "      <th>numTag</th>\n",
       "      <th>token</th>\n",
       "      <th>numToken</th>\n",
       "      <th>numChar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ฝุ่น PM2.5 : ทส.เตรียมตั้งศูนย์แก้ปัญหาหมอกควั...</td>\n",
       "      <td>05/04/2562</td>\n",
       "      <td>FRI</td>\n",
       "      <td>19:37</td>\n",
       "      <td>177</td>\n",
       "      <td>สิ่งแวดล้อม</td>\n",
       "      <td>ฝุ่นเชียงใหม่,ฝุ่นPM2.5,ฝุ่นคลุมเมือง,เชียงใหม...</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>ฝุ่น,PM,ทส.,เตรียม,ตั้ง,ศูนย์,แก้,ปัญหา,หมอก,ค...</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>เลือกตั้ง 2562 : \"เพื่อไทย\" เตรียมยื่น กกต.จัด...</td>\n",
       "      <td>05/04/2562</td>\n",
       "      <td>FRI</td>\n",
       "      <td>19:20</td>\n",
       "      <td>702</td>\n",
       "      <td>การเมือง</td>\n",
       "      <td>เลือกตั้ง62,เพื่อ่ไทย,กกต.,นับคะแนน,ไทยพีบีเอส...</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>เลือกตั้ง,2562,เพื่อ,ไทย,เตรียม,ยื่น,กกต.,จัด,...</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>เตรียมเอาผิด รพ.เอกชน 58 แห่งไม่ส่งข้อมูลราคายา</td>\n",
       "      <td>05/04/2562</td>\n",
       "      <td>FRI</td>\n",
       "      <td>19:18</td>\n",
       "      <td>583</td>\n",
       "      <td>สาธารณสุข</td>\n",
       "      <td>ยา,เวชภัณฑ์ฯ,โรงพยาบาล,ค่าบริการทางการแพทย์,กร...</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>เตรียม,เอา,ผิด,รพ.เอกชน,แห่ง,ไม่,ส่ง,ข้อมูล,รา...</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ตั้งข้อสังเกตปลดล็อกกัญชา เอื้อนายทุนหรือไม่?</td>\n",
       "      <td>05/04/2562</td>\n",
       "      <td>FRI</td>\n",
       "      <td>19:16</td>\n",
       "      <td>928</td>\n",
       "      <td>อาชญากรรม</td>\n",
       "      <td>กัญชา,มูลนิธิข้าวขวัญ,ThaiPBSnews</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>ตั้ง,ข้อ,สังเกต,ปลด,ล็อก,กัญชา,เอื้อ,นาย,ทุน,ห...</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>คำพิพากษาเต็ม \"เปรมชัย\" หลุดคดีครอบครองซากเสือดำ</td>\n",
       "      <td>05/04/2562</td>\n",
       "      <td>FRI</td>\n",
       "      <td>19:29</td>\n",
       "      <td>5163</td>\n",
       "      <td>สิ่งแวดล้อม</td>\n",
       "      <td>เสือดำ,เปรมชัย,เขตรักษาพันธุ์สัตว์ป่าทุ่งใหญ่น...</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>คำ,พิพากษา,เต็ม,เปรมชัย,หลุดคดี,ครอบครอง,ซาก,เ...</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                                           headline  \\\n",
       "0             0  ฝุ่น PM2.5 : ทส.เตรียมตั้งศูนย์แก้ปัญหาหมอกควั...   \n",
       "1             1  เลือกตั้ง 2562 : \"เพื่อไทย\" เตรียมยื่น กกต.จัด...   \n",
       "2             2    เตรียมเอาผิด รพ.เอกชน 58 แห่งไม่ส่งข้อมูลราคายา   \n",
       "3             3      ตั้งข้อสังเกตปลดล็อกกัญชา เอื้อนายทุนหรือไม่?   \n",
       "4             4   คำพิพากษาเต็ม \"เปรมชัย\" หลุดคดีครอบครองซากเสือดำ   \n",
       "\n",
       "         date  DOW   time  view     category  \\\n",
       "0  05/04/2562  FRI  19:37   177  สิ่งแวดล้อม   \n",
       "1  05/04/2562  FRI  19:20   702     การเมือง   \n",
       "2  05/04/2562  FRI  19:18   583    สาธารณสุข   \n",
       "3  05/04/2562  FRI  19:16   928    อาชญากรรม   \n",
       "4  05/04/2562  FRI  19:29  5163  สิ่งแวดล้อม   \n",
       "\n",
       "                                                 tag  hour  numTag  \\\n",
       "0  ฝุ่นเชียงใหม่,ฝุ่นPM2.5,ฝุ่นคลุมเมือง,เชียงใหม...    19      10   \n",
       "1  เลือกตั้ง62,เพื่อ่ไทย,กกต.,นับคะแนน,ไทยพีบีเอส...    19       6   \n",
       "2  ยา,เวชภัณฑ์ฯ,โรงพยาบาล,ค่าบริการทางการแพทย์,กร...    19       9   \n",
       "3                  กัญชา,มูลนิธิข้าวขวัญ,ThaiPBSnews    19       3   \n",
       "4  เสือดำ,เปรมชัย,เขตรักษาพันธุ์สัตว์ป่าทุ่งใหญ่น...    19       5   \n",
       "\n",
       "                                               token  numToken  numChar  \n",
       "0  ฝุ่น,PM,ทส.,เตรียม,ตั้ง,ศูนย์,แก้,ปัญหา,หมอก,ค...        12       47  \n",
       "1  เลือกตั้ง,2562,เพื่อ,ไทย,เตรียม,ยื่น,กกต.,จัด,...        12       58  \n",
       "2  เตรียม,เอา,ผิด,รพ.เอกชน,แห่ง,ไม่,ส่ง,ข้อมูล,รา...        10       42  \n",
       "3  ตั้ง,ข้อ,สังเกต,ปลด,ล็อก,กัญชา,เอื้อ,นาย,ทุน,ห...        11       43  \n",
       "4  คำ,พิพากษา,เต็ม,เปรมชัย,หลุดคดี,ครอบครอง,ซาก,เ...         8       44  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQRval = input_pbs['view'].describe().loc['75%']-input_pbs['view'].describe().loc['25%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3499.5\n"
     ]
    }
   ],
   "source": [
    "outlierMin = max(input_pbs['view'].describe().loc['25%']-1.5*IQRval,0)\n",
    "outlierMax = input_pbs['view'].describe().loc['75%']+1.5*IQRval\n",
    "print(outlierMin,outlierMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pbs = input_pbs[(input_pbs['view']<=outlierMax) & (input_pbs['view']>=outlierMin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24511.000000\n",
       "mean        11.389662\n",
       "std          3.354892\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         11.000000\n",
       "75%         13.000000\n",
       "max         28.000000\n",
       "Name: numToken, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pbs['numToken'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24511.000000\n",
       "mean       755.928603\n",
       "std        754.956352\n",
       "min         20.000000\n",
       "25%        228.000000\n",
       "50%        454.000000\n",
       "75%       1006.000000\n",
       "max       3496.000000\n",
       "Name: view, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pbs['view'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3496"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAXVIEW = input_pbs['view'].max()\n",
    "MAXVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = []\n",
    "for sent in input_pbs['token']:\n",
    "    inputText.append(sent.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLabel = []\n",
    "for view in input_pbs['view']:\n",
    "    inputLabel.append(view/MAXVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24511 24511\n"
     ]
    }
   ],
   "source": [
    "print(len(inputText),len(inputLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in inputText:\n",
    "    for word in sentence:\n",
    "        words.append(word)\n",
    "        \n",
    "word_count = list()\n",
    "word_count.extend(collections.Counter(words).most_common(len(set(words))))\n",
    "word_count = word_count[:len(word_count)//4]\n",
    "word_count.append((\"UNK\",0))\n",
    "\n",
    "train_word = set()\n",
    "for i in word_count:\n",
    "    train_word.add(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4955"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token = set()\n",
    "for word in train_word:\n",
    "    all_token.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token = list(all_token)\n",
    "all_token.insert(0,'for padding')\n",
    "all_token.insert(1,'UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4957"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_map = dict(zip(all_token, range(len(all_token))))\n",
    "token_map_reverse = dict(zip(range(len(all_token)),all_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.asarray(input_pbs['token'].str.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word(sent):\n",
    "    global all_token, token_map\n",
    "    result = np.zeros(len(all_token))\n",
    "    np_token = np.array(sent)\n",
    "    str_token, str_token_count = np.unique(np_token, return_counts=True)\n",
    "    for char, count in zip(str_token, str_token_count):\n",
    "        if char not in token_map.keys():\n",
    "            char = 'UNK'\n",
    "        result[token_map[char]] = count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.vectorize(count_word, otypes=[object])(input_data)\n",
    "x_f1 = np.array([[e for e in sl] for sl in temp.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=keras.preprocessing.sequence.pad_sequences(x_f1, maxlen=None, dtype='int32', padding='post', truncating='pre', value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24511, 4957)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test =  train_test_split(x_train, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (19608, 4957)\n",
      "test size (4903, 4957)\n"
     ]
    }
   ],
   "source": [
    "print(\"train size\",x_train.shape)\n",
    "print(\"test size\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = inputLabel\n",
    "y_train = np.asarray(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test =  train_test_split(y_train, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 19608\n",
      "test size 4903\n"
     ]
    }
   ],
   "source": [
    "print(\"train size\",len(y_train))\n",
    "print(\"test size\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    input1 = Input(shape=(x_train.shape[1],))\n",
    "    x = Dense(1024, activation='relu')(input1)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization(momentum=0.99, epsilon=0.001)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization(momentum=0.99, epsilon=0.001)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization(momentum=0.99, epsilon=0.001)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization(momentum=0.99, epsilon=0.001)(x)\n",
    "    x = Dense(1,activation='linear')(x)\n",
    "    model = Model(inputs=input1, outputs=x)\n",
    "    adam  = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam,  loss='mean_absolute_percentage_error')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4957)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              5076992   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,362,337\n",
      "Trainable params: 5,359,617\n",
      "Non-trainable params: 2,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path='./model_baseline_test1_withstop.h5'\n",
    "callbacks_list = [\n",
    "        ModelCheckpoint(\n",
    "            weight_path,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15686 samples, validate on 3922 samples\n",
      "Epoch 1/50\n",
      "15686/15686 [==============================] - 11s 699us/step - loss: 954.3705 - val_loss: 512.9504\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 512.95036, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 2/50\n",
      "15686/15686 [==============================] - 9s 551us/step - loss: 773.2786 - val_loss: 377.1626\n",
      "\n",
      "Epoch 00002: val_loss improved from 512.95036 to 377.16264, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 3/50\n",
      "15686/15686 [==============================] - 9s 549us/step - loss: 647.8586 - val_loss: 291.9656\n",
      "\n",
      "Epoch 00003: val_loss improved from 377.16264 to 291.96558, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 4/50\n",
      "15686/15686 [==============================] - 9s 550us/step - loss: 531.7727 - val_loss: 238.9477\n",
      "\n",
      "Epoch 00004: val_loss improved from 291.96558 to 238.94772, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 5/50\n",
      "15686/15686 [==============================] - 9s 543us/step - loss: 451.7698 - val_loss: 203.5024\n",
      "\n",
      "Epoch 00005: val_loss improved from 238.94772 to 203.50239, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 6/50\n",
      "15686/15686 [==============================] - 8s 535us/step - loss: 383.2588 - val_loss: 165.3889\n",
      "\n",
      "Epoch 00006: val_loss improved from 203.50239 to 165.38887, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 7/50\n",
      "15686/15686 [==============================] - 8s 542us/step - loss: 316.3060 - val_loss: 133.8463\n",
      "\n",
      "Epoch 00007: val_loss improved from 165.38887 to 133.84631, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 8/50\n",
      "15686/15686 [==============================] - 8s 541us/step - loss: 264.6079 - val_loss: 113.3151\n",
      "\n",
      "Epoch 00008: val_loss improved from 133.84631 to 113.31511, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 9/50\n",
      "15686/15686 [==============================] - 8s 541us/step - loss: 219.4833 - val_loss: 94.3428\n",
      "\n",
      "Epoch 00009: val_loss improved from 113.31511 to 94.34282, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 10/50\n",
      "15686/15686 [==============================] - 9s 551us/step - loss: 175.7633 - val_loss: 78.7422\n",
      "\n",
      "Epoch 00010: val_loss improved from 94.34282 to 78.74224, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 11/50\n",
      "15686/15686 [==============================] - 9s 548us/step - loss: 142.2461 - val_loss: 70.8339\n",
      "\n",
      "Epoch 00011: val_loss improved from 78.74224 to 70.83393, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 12/50\n",
      "15686/15686 [==============================] - 8s 542us/step - loss: 117.2172 - val_loss: 67.4609\n",
      "\n",
      "Epoch 00012: val_loss improved from 70.83393 to 67.46087, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 13/50\n",
      "15686/15686 [==============================] - 9s 542us/step - loss: 99.5726 - val_loss: 62.7510\n",
      "\n",
      "Epoch 00013: val_loss improved from 67.46087 to 62.75098, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 14/50\n",
      "15686/15686 [==============================] - 9s 552us/step - loss: 89.8476 - val_loss: 62.0647\n",
      "\n",
      "Epoch 00014: val_loss improved from 62.75098 to 62.06474, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 15/50\n",
      "15686/15686 [==============================] - 9s 553us/step - loss: 81.3073 - val_loss: 62.3625\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 62.06474\n",
      "Epoch 16/50\n",
      "15686/15686 [==============================] - 9s 585us/step - loss: 77.8748 - val_loss: 61.7738\n",
      "\n",
      "Epoch 00016: val_loss improved from 62.06474 to 61.77383, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 17/50\n",
      "15686/15686 [==============================] - 9s 557us/step - loss: 72.9158 - val_loss: 61.4369\n",
      "\n",
      "Epoch 00017: val_loss improved from 61.77383 to 61.43694, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 18/50\n",
      "15686/15686 [==============================] - 9s 550us/step - loss: 70.2404 - val_loss: 60.9163\n",
      "\n",
      "Epoch 00018: val_loss improved from 61.43694 to 60.91632, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 19/50\n",
      "15686/15686 [==============================] - 9s 545us/step - loss: 68.0302 - val_loss: 60.3660\n",
      "\n",
      "Epoch 00019: val_loss improved from 60.91632 to 60.36601, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 20/50\n",
      "15686/15686 [==============================] - 8s 540us/step - loss: 65.1915 - val_loss: 60.1889\n",
      "\n",
      "Epoch 00020: val_loss improved from 60.36601 to 60.18888, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 21/50\n",
      "15686/15686 [==============================] - 8s 539us/step - loss: 63.3052 - val_loss: 59.6138\n",
      "\n",
      "Epoch 00021: val_loss improved from 60.18888 to 59.61376, saving model to ./model_baseline_test1_withstop.h5\n",
      "Epoch 22/50\n",
      "15686/15686 [==============================] - 8s 538us/step - loss: 61.2859 - val_loss: 59.9334\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 59.61376\n",
      "Epoch 23/50\n",
      "15686/15686 [==============================] - 8s 540us/step - loss: 58.5905 - val_loss: 59.7523\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 59.61376\n",
      "Epoch 24/50\n",
      "15686/15686 [==============================] - 9s 549us/step - loss: 56.9544 - val_loss: 59.7921\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 59.61376\n",
      "Epoch 25/50\n",
      "15686/15686 [==============================] - 9s 545us/step - loss: 55.4691 - val_loss: 60.5308\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 59.61376\n",
      "Epoch 26/50\n",
      "15686/15686 [==============================] - 9s 554us/step - loss: 53.3828 - val_loss: 60.3631\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 59.61376\n",
      "Epoch 27/50\n",
      "15686/15686 [==============================] - 9s 560us/step - loss: 52.0430 - val_loss: 61.0387\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 59.61376\n",
      "Epoch 28/50\n",
      "15686/15686 [==============================] - 9s 549us/step - loss: 50.7698 - val_loss: 61.1130\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 59.61376\n",
      "Epoch 29/50\n",
      "15686/15686 [==============================] - 9s 549us/step - loss: 49.3195 - val_loss: 61.2525\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 59.61376\n",
      "Epoch 30/50\n",
      "15686/15686 [==============================] - 9s 547us/step - loss: 48.3063 - val_loss: 62.1751\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 59.61376\n",
      "Epoch 31/50\n",
      "15686/15686 [==============================] - 9s 548us/step - loss: 47.2381 - val_loss: 62.7426\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 59.61376\n",
      "Epoch 32/50\n",
      "15686/15686 [==============================] - 9s 548us/step - loss: 46.4360 - val_loss: 63.4752\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 59.61376\n",
      "Epoch 33/50\n",
      "15686/15686 [==============================] - 8s 539us/step - loss: 45.2535 - val_loss: 63.9897\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 59.61376\n",
      "Epoch 34/50\n",
      "15686/15686 [==============================] - 9s 556us/step - loss: 44.4020 - val_loss: 64.7360\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 59.61376\n",
      "Epoch 35/50\n",
      "15686/15686 [==============================] - 9s 562us/step - loss: 43.4791 - val_loss: 65.9374\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 59.61376\n",
      "Epoch 36/50\n",
      "15686/15686 [==============================] - 9s 562us/step - loss: 42.8219 - val_loss: 66.4652\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 59.61376\n",
      "Epoch 37/50\n",
      "15686/15686 [==============================] - 9s 560us/step - loss: 42.4450 - val_loss: 66.2905\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 59.61376\n",
      "Epoch 38/50\n",
      "15686/15686 [==============================] - 9s 565us/step - loss: 41.4202 - val_loss: 68.2656\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 59.61376\n",
      "Epoch 39/50\n",
      "15686/15686 [==============================] - 9s 558us/step - loss: 41.2374 - val_loss: 68.9015\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 59.61376\n",
      "Epoch 40/50\n",
      "15686/15686 [==============================] - 9s 576us/step - loss: 40.4617 - val_loss: 68.8689\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 59.61376\n",
      "Epoch 41/50\n",
      "15686/15686 [==============================] - 9s 568us/step - loss: 40.1274 - val_loss: 69.5374\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 59.61376\n",
      "Epoch 42/50\n",
      "15686/15686 [==============================] - 9s 564us/step - loss: 39.2531 - val_loss: 70.1998\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 59.61376\n",
      "Epoch 43/50\n",
      "15686/15686 [==============================] - 9s 585us/step - loss: 38.9408 - val_loss: 70.8893\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 59.61376\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15686/15686 [==============================] - 9s 579us/step - loss: 38.5271 - val_loss: 71.9759\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 59.61376\n",
      "Epoch 45/50\n",
      "15686/15686 [==============================] - 9s 569us/step - loss: 38.0019 - val_loss: 72.2046\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 59.61376\n",
      "Epoch 46/50\n",
      "15686/15686 [==============================] - 8s 536us/step - loss: 37.5012 - val_loss: 71.7771\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 59.61376\n",
      "Epoch 47/50\n",
      "15686/15686 [==============================] - 8s 538us/step - loss: 36.9583 - val_loss: 73.3397\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 59.61376\n",
      "Epoch 48/50\n",
      "15686/15686 [==============================] - 8s 539us/step - loss: 36.7325 - val_loss: 72.8213\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 59.61376\n",
      "Epoch 49/50\n",
      "15686/15686 [==============================] - 9s 549us/step - loss: 36.6312 - val_loss: 73.2935\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 59.61376\n",
      "Epoch 50/50\n",
      "15686/15686 [==============================] - 9s 542us/step - loss: 36.1913 - val_loss: 73.9639\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 59.61376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2f967a128>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32 ,epochs=50, verbose=1, validation_split=0.2,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15686 samples, validate on 3922 samples\n",
      "Epoch 1/5\n",
      "15686/15686 [==============================] - 9s 595us/step - loss: 36.5602 - val_loss: 72.7645\n",
      "Epoch 2/5\n",
      "  320/15686 [..............................] - ETA: 8s - loss: 33.7238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burin/.env/src/keras/keras/callbacks.py:707: RuntimeWarning: Can save best model only with train_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15686/15686 [==============================] - 9s 584us/step - loss: 36.2576 - val_loss: 73.2490\n",
      "Epoch 3/5\n",
      "15686/15686 [==============================] - 9s 588us/step - loss: 36.2094 - val_loss: 73.4807\n",
      "Epoch 4/5\n",
      "15686/15686 [==============================] - 9s 585us/step - loss: 35.4603 - val_loss: 74.0365\n",
      "Epoch 5/5\n",
      "15686/15686 [==============================] - 9s 555us/step - loss: 35.9419 - val_loss: 75.4226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6cdc47550>"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32 ,epochs=5, verbose=1, validation_split=0.2,callbacks=callbacks_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_model='./model_baseline_test2.h5'\n",
    "model = create_model()\n",
    "model.load_weights(weight_model)\n",
    "model._make_predict_function()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = y_pred.clip(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds, testY):\n",
    "    diff = preds.flatten() - testY\n",
    "    percentDiff = (diff / testY) * 100\n",
    "    absPercentDiff = np.abs(percentDiff)\n",
    "    mean = np.mean(absPercentDiff)\n",
    "    std = np.std(absPercentDiff)\n",
    "    print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.5437980900978 150.8995226451807\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.73933719442356 147.63111233841977\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.36952848213208 128.7975869594508\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_pred2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104.] [0.04379225]\n",
      "[104.] [153.09772]\n",
      "[97.] [0.09940206]\n",
      "[97.] [347.50958]\n",
      "[94.] [0.05182158]\n",
      "[94.] [181.16824]\n",
      "[165.] [0.05189327]\n",
      "[165.] [181.41887]\n",
      "[724.] [0.11034767]\n",
      "[724.] [385.77545]\n",
      "[254.] [0.08795989]\n",
      "[254.] [307.50778]\n",
      "[1483.] [0.04845521]\n",
      "[1483.] [169.39943]\n",
      "[1490.] [0.1522605]\n",
      "[1490.] [532.3027]\n",
      "[360.] [0.11586411]\n",
      "[360.] [405.06094]\n",
      "[2805.] [0.11565819]\n",
      "[2805.] [404.34103]\n",
      "[3094.] [0.2553892]\n",
      "[3094.] [892.8407]\n",
      "[184.] [0.08681615]\n",
      "[184.] [303.50928]\n",
      "[231.] [0.16967946]\n",
      "[231.] [593.1994]\n",
      "[364.] [0.1624019]\n",
      "[364.] [567.757]\n",
      "[393.] [0.11865829]\n",
      "[393.] [414.82938]\n",
      "[479.] [0.10168976]\n",
      "[479.] [355.50742]\n",
      "[210.] [0.05912689]\n",
      "[210.] [206.70763]\n",
      "[423.] [0.0515598]\n",
      "[423.] [180.25307]\n",
      "[1278.] [0.07914282]\n",
      "[1278.] [276.68332]\n",
      "[2179.] [0.21793026]\n",
      "[2179.] [761.88416]\n",
      "[130.] [0.05533054]\n",
      "[130.] [193.43558]\n",
      "[73.] [0.06416036]\n",
      "[73.] [224.30463]\n",
      "[351.] [0.1459571]\n",
      "[351.] [510.26602]\n",
      "[127.] [0.05311427]\n",
      "[127.] [185.68747]\n",
      "[1788.] [0.1731593]\n",
      "[1788.] [605.3649]\n",
      "[195.] [0.06459923]\n",
      "[195.] [225.83891]\n",
      "[164.] [0.08727887]\n",
      "[164.] [305.12692]\n",
      "[211.] [0.15559727]\n",
      "[211.] [543.9681]\n",
      "[979.] [0.0619997]\n",
      "[979.] [216.75096]\n",
      "[470.] [0.11098154]\n",
      "[470.] [387.99146]\n",
      "[215.] [0.04756558]\n",
      "[215.] [166.28926]\n",
      "[349.] [0.03920215]\n",
      "[349.] [137.05074]\n",
      "[791.] [0.18873864]\n",
      "[791.] [659.8303]\n",
      "[920.] [0.07589957]\n",
      "[920.] [265.3449]\n",
      "[1229.] [0.28568518]\n",
      "[1229.] [998.7554]\n",
      "[2776.] [0.05495491]\n",
      "[2776.] [192.12236]\n",
      "[1981.] [0.06720049]\n",
      "[1981.] [234.9329]\n",
      "[247.] [0.10319357]\n",
      "[247.] [360.7647]\n",
      "[850.] [0.20664978]\n",
      "[850.] [722.44763]\n",
      "[799.] [0.08024522]\n",
      "[799.] [280.5373]\n",
      "[510.] [0.26614487]\n",
      "[510.] [930.44244]\n",
      "[57.] [0.10756209]\n",
      "[57.] [376.03708]\n",
      "[278.] [0.04884308]\n",
      "[278.] [170.7554]\n",
      "[349.] [0.11430211]\n",
      "[349.] [399.6002]\n",
      "[1090.] [0.2235215]\n",
      "[1090.] [781.43115]\n",
      "[226.] [0.04306592]\n",
      "[226.] [150.55846]\n",
      "[222.] [0.0869297]\n",
      "[222.] [303.90625]\n",
      "[524.] [0.19793814]\n",
      "[524.] [691.99176]\n",
      "[141.] [0.05290589]\n",
      "[141.] [184.95898]\n",
      "[260.] [0.05771632]\n",
      "[260.] [201.77625]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(y_test2[i],y_pred2[i])\n",
    "    print(y_test2[i],y_pred2[i]*MAXVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
